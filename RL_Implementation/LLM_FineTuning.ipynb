{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Fine-Tuning LLM for Haiku Structure </H1>\n",
    "https://github.com/davanstrien/haiku-dpo <br>\n",
    "https://github.com/glakshay/Generating-Haiku-using-GAN/tree/master/dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elyas/Desktop/ImageToPoem/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nGPT2LMHeadModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load the pre-trained GPT-2 model and tokenizer\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m GPT2LMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m GPT2Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Load your haiku dataset (custom or from a source like Kaggle)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ImageToPoem/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1651\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1651\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[0;32m~/Desktop/ImageToPoem/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1639\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1637\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[1;32m   1638\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m-> 1639\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nGPT2LMHeadModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load your haiku dataset (custom or from a source like Kaggle)\n",
    "dataset = load_dataset(\"path_to_haiku_dataset\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_haiku_model\", # Where to save the fine-tuned model\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',  # For logging\n",
    ")\n",
    "\n",
    "# Set up the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./gpt2_finetuned_haiku\")\n",
    "tokenizer.save_pretrained(\"./gpt2_finetuned_haiku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Detector </h2>\n",
    "<P>\n",
    "poem_lines = [\n",
    "    \"Autumn leaves fall\",  # 4 syllables (violation) <br>\n",
    "    \"Swirling in the cold wind\",  # 7 syllables (correct)<br>\n",
    "    \"A silent forest\"  # 5 syllables (correct)<br>\n",
    "]\n",
    "\n",
    "\n",
    "violations = [(0, 4)]  # Line 0 violates syllable count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msyllapy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_line_violations\u001b[39m(poem_lines):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/elyas/Desktop/ImageToPoem/RL_Implementation/LLM_FineTuning.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Define the target syllable pattern for haiku (5-7-5)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import syllapy\n",
    "\n",
    "def detect_line_violations(poem_lines):\n",
    "    # Define the target syllable pattern for haiku (5-7-5)\n",
    "    target_syllables = [5, 7, 5]\n",
    "    \n",
    "    violations = []\n",
    "    \n",
    "    # Check syllable count for each line\n",
    "    for i, line in enumerate(poem_lines):\n",
    "        syllable_count = sum(syllapy.count(word) for word in word_tokenize(line))\n",
    "        if syllable_count != target_syllables[i]:\n",
    "            violations.append((i, syllable_count))  # Record line index and its syllable count\n",
    "    \n",
    "    return violations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prompter </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_haiku_suggestion(poem_context, target_syllables, model, tokenizer):\n",
    "    prompt = f\"Continue this haiku: {poem_context} (Target syllable count: {target_syllables})\"\n",
    "    \n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=50, num_return_sequences=3, temperature=0.7, top_k=50)\n",
    "    \n",
    "    suggestions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    return suggestions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Haiku Generation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"Autumn leaves fall, swirling in the cold wind, a silent forest.\"\n",
    "poem_lines = poem.split(\", \")\n",
    "\n",
    "# Detect violations\n",
    "violations = detect_line_violations(poem_lines)\n",
    "\n",
    "# If there are violations, prompt for replacements\n",
    "for violation in violations:\n",
    "    line_idx, syllable_count = violation\n",
    "    target_syllables = 5 if line_idx == 0 else 7  # Adjust target syllables based on line\n",
    "    suggestions = generate_haiku_suggestion(poem, target_syllables, model, tokenizer)\n",
    "    print(f\"Suggestions for line {line_idx}: {suggestions}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
